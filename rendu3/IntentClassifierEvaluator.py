from collections import Counter
import numpy as np
from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

class IntentClassifierEvaluator:
    """
    Classe utilitaire pour √©valuer un classificateur d'intentions (IntentClassifier)
    sur un jeu de donn√©es, avec gestion automatique du split train/test ou
    validation crois√©e Leave-One-Out selon la taille du dataset.
    Fournit aussi des tests obligatoires sur des phrases personnalis√©es.
    """
    def __init__(self, classifier, texts, labels):
        """
        Initialise l'√©valuateur avec un classificateur, les textes et les labels.
        
        Args:
            classifier: Instance de la classe IntentClassifier (ou pipeline compatible sklearn).
            texts (list of str): Liste des phrases d'entra√Ænement.
            labels (list of str): Liste des labels/intents correspondants.
        """
        self.classifier = classifier
        self.texts = texts
        self.labels = labels

    def evaluate(self):
        """
        √âvalue le classificateur sur le dataset fourni.
        - Si le dataset est suffisant, effectue un split train/test (80/20) stratifi√©.
        - Sinon, effectue une validation crois√©e Leave-One-Out.
        Affiche pr√©cision, rappel, F1-score, matrice de confusion et rapport d√©taill√©.
        """

        class_counts = Counter(self.labels)
        min_samples_per_class = min(class_counts.values())
        total_classes = len(class_counts)
        test_size = max(1, int(0.2 * len(self.texts)))

        print(f"\nüìä Donn√©es d'entra√Ænement pr√©par√©es:")
        print(f"   - Nombre d'exemples: {len(self.texts)}")
        print(f"   - Intentions disponibles: {set(self.labels)}")
        for intention in set(self.labels):
            count = self.labels.count(intention)
            print(f"     ‚Ä¢ {intention}: {count} exemples")

        if len(self.texts) == 0:
            print("‚ùå Aucune donn√©e d'entra√Ænement trouv√©e dans le dataset!")
            return

        if test_size < total_classes or min_samples_per_class < 2:
            print("\n‚ö†Ô∏è  Dataset trop petit ou test set trop petit pour un split train/test stratifi√©.")
            print(f"   - Total d'exemples: {len(self.texts)}")
            print(f"   - Nombre de classes: {total_classes}")
            print(f"   - Minimum d'exemples par classe: {min_samples_per_class}")
            print(f"   - Taille du test set calcul√©e: {test_size}")
            print(f"   - Utilisation de validation crois√©e Leave-One-Out.")
            loo = LeaveOneOut()
            scores = cross_val_score(self.classifier.pipeline, np.array(self.texts), np.array(self.labels), cv=loo, scoring='accuracy')
            print(f"Pr√©cision Leave-One-Out: {scores.mean():.2f} ¬± {scores.std():.2f}")
            if scores.mean() > 0.8:
                print(f"üéØ Objectif atteint ! Pr√©cision > 80%")
            else:
                print(f"‚ùå Objectif non atteint. Pr√©cision: {scores.mean()*100:.1f}%")
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                self.texts, self.labels, test_size=0.2, random_state=42, stratify=self.labels)
            self.classifier.train(X_train, y_train)
            y_pred = self.classifier.pipeline.predict(X_test)
            acc = accuracy_score(y_test, y_pred)
            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
            print(f"\nPr√©cision: {acc:.2f}")
            print(f"Rappel: {rec:.2f}")
            print(f"F1-score: {f1:.2f}")
            print(f"\nMatrice de confusion:")
            print(confusion_matrix(y_test, y_pred))
            print(f"\nRapport d√©taill√©:\n{classification_report(y_test, y_pred)}")
            if acc > 0.8:
                print(f"üéØ Objectif atteint ! Pr√©cision > 80%")
            else:
                print(f"‚ùå Objectif non atteint. Pr√©cision: {acc*100:.1f}%")
        print("\n‚úÖ √âvaluation termin√©e!")
        print("=" * 60)

    def test_obligatoires(self):
        """
        Entra√Æne le classificateur sur toutes les donn√©es et pr√©dit l'intention
        pour un ensemble de phrases de test obligatoires. Affiche le r√©sultat pour chaque phrase.
        """
        # Toujours entra√Æner sur tout le dataset avant les tests obligatoires
        self.classifier.train(self.texts, self.labels)
        print("\nüß™ Tests obligatoires sur des phrases personnalis√©es :")
        test_phrases = [
            "Bonsoir, je souhaiterais voir votre menu",
            "√Ä quelle heure fermez-vous le dimanche ?",
            "Combien co√ªte une pizza Regina ?",
            "Je veux commander trois pizzas margherita"
        ]
        for phrase in test_phrases:
            prediction = self.classifier.predict(phrase)
            print(f"  ‚Üí '{phrase}'  =>  intention pr√©dite : {prediction[0]}")
